{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처 \\\n",
    "https://www.kaggle.com/code/aharless/xgboost-cv-lb-284/notebook \\\n",
    "https://kubig-2021-2.tistory.com/38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ROUNDS = 400\n",
    "OPTIMIZE_ROUNDS = False\n",
    "LEARNING_RATE = 0.07\n",
    "EARLY_STOPPING_ROUNDS = 10\n",
    "# EARLY_STOPPING_ROUNDS를 매우 높게 설정하였습니다.(50, OPTIMIZE_ROUNDS가 설정되어 있을 때)\n",
    "# 실제로 early stopping을 사용하고 싶다면 EARLY_STOPPING_ROUNDS를 줄여주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rounds의 적절한 수에 대한 아이디어를 얻기 위해 초기에 MAX_ROUNDS를 매우 높게 설정하고 OPTIMIZE_ROUNDS를 사용하는 것을 추천합니다. (모든 fold 중에서 $best\\_ntree\\_limit$의 최댓값에 가까워야하며 모델이 적절하게 정규화되었다면 조금 더 높을 수 있습니다. 아니면 $verbose=True$로 설정하여 디테일을 살펴본 후 모든 fold에 잘 작동되는 round를 찾습니다). 그 후, OPTIMIZEZ_ROUNDS를 끄고, 최적의 MAX_ROUNDS의 값을 설정합니다.\n",
    "\n",
    "각 fold에서 가장 적합한 round를 설정해 early stopping하는 가장 큰 문제점은 validation data에 overfitting된다는 것입니다. 그러므로 test data를 예측하는데 최적의 모델을 만들지 못할 가능성이 있고, 만약 다른 모델과의 stacking/ensembling을 위한 validation data를 생성하는데 사용된다면 이 모델이 앙상블에 너무 많은 weight을 갖게 됩니다. 또 다른 가능성(XGBoost의 default)은 최적의 round보다 early stopping이 일어났을때의 round를 사용한다는 것입니다.\n",
    "\n",
    "early stopping이 overfitting 문제는 해결하지만, 20-round early stopping에서 일정한 값의 round보다 validation score가 낮게 나온 것을 봤을때, early stopping은 약간 underfitting된 것처럼 보입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numba import jit\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gini\n",
    "\n",
    "@jit # 넘파이 코드를 빠르게 실행시켜주는 JIT 컴파일러\n",
    "def eval_gini(y_true, y_prob):\n",
    "    y_true = np.asarray(y_true) # numba가 이해할 수 있는 형식으로 변환\n",
    "    y_true = y_true[np.argsort(y_prob)]\n",
    "    ntrue = 0\n",
    "    gini = 0\n",
    "    delta = 0\n",
    "    n = len(y_true)\n",
    "    for i in range(n-1, -1, -1):\n",
    "        y_i = y_true[i]\n",
    "        ntrue += y_i\n",
    "        gini += y_i * delta\n",
    "        delta += 1 - y_i\n",
    "    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = -eval_gini(labels, preds)\n",
    "    # 해당 커널에서 분류에 사용한 XGBClassifier모델은 평가 지표로 rmse와 같은 값을 사용 -> 즉 오류의 최솟값을 찾음\n",
    "    # 이 대회의 평가 지표인 지니 계수 : 0.5에 가까울수록(값이 클수록) 좋은 값이기 때문에 -를 붙여주는 함수를 생성\n",
    "    return [(\"gini\", gini_score)]"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**범주형 변수 인코딩**\n",
    "\n",
    "해당 커널에서는 distinct value가 많은 ps_car_11_cat 변수들에 대해서는 mean encoding을 사용하였고, 나머지 범주형 변수들에 대해서는 더미 변수를 생성하는 one-hot encoding의 방식 사용\n",
    "\n",
    " \n",
    "\n",
    "**Mean encoding이란?**\n",
    "\n",
    "<목표>\n",
    "\n",
    "카테고리 변수에 대하여 (여기서는 104개의 카테고리를 가진 ps_car_11_cat 변수에 대하여) 단순하게 0,1로 구분된 target값에 대한 의미를 가지도록 만드는 것\n",
    "\n",
    " \n",
    "\n",
    "<Method>\n",
    "\n",
    "카테고리 변수의 Label 값에 따라서 Target 값의 평균을 구해 각 Label이 Target과 가지는 상관성, 영향 도출\n",
    "\n",
    " \n",
    "\n",
    "<문제점>\n",
    "\n",
    " \n",
    "\n",
    "1. target값을 이용해 계산하기 때문에 overfitting의 문제가 발생할 수 있음 -> 이 커널에서는 noise를 추가하는 방식으로 이 문제를 해결\n",
    "\n",
    " \n",
    "\n",
    "2. test 데이터와 train 데이터 간의 분포가 다른 경우 (ex. 한쪽이 불균형 데이터인 경우) 이때도 마찬가지로 overfitting의 문제 발생 가능 -> Smoothing을 통해 문제 해결\n",
    "\n",
    " \n",
    "\n",
    "Smoothing 공식\n",
    "    \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(series, noise_level):\n",
    "    return series * (1 + noise_level * np.random.randn(len(series)))\n",
    "\n",
    "def target_encode(trn_series=None, \n",
    "                  val_series=None,\n",
    "                  tst_series=None,\n",
    "                  target=None,\n",
    "                  min_samples_leaf=1,\n",
    "                  smoothing=1,\n",
    "                  noise_level=0):\n",
    "    '''\n",
    "    trn_series : training categorical feature as a pd.Series\n",
    "    tst_series : test categorical feature as a pd.Series\n",
    "    target : target data as a pd.Series\n",
    "    min_samples_leaf (int): category 평균을 고려하기 위한 최소 샘플 수\n",
    "    smoothing (int): categorical average와 prior의 균형을 맞추기 위한 smoothing effect\n",
    "    '''\n",
    "    assert len(trn_series) == len(target)\n",
    "    assert trn_series.name == tst_series.name\n",
    "    temp = pd.concat([trn_series, target], axis=1)\n",
    "    # Compute target mean\n",
    "    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n",
    "    \n",
    "    # Compute smoothing\n",
    "    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n",
    "    \n",
    "    # Apply average function to all target data\n",
    "    prior = target.mean()\n",
    "    \n",
    "    # The bigger the count the less full_avg is taken into account\n",
    "    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n",
    "    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n",
    "    \n",
    "    # Apply averages to trn and tst series\n",
    "    ft_trn_series = pd.merge(\n",
    "        trn_series.to_frame(trn_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=trn_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_trn_series.index = trn_series.index\n",
    "    ft_val_series = pd.merge(\n",
    "        val_series.to_frame(val_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=val_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_val_series.index = val_series.index\n",
    "    ft_tst_series = pd.merge(\n",
    "        tst_series.to_frame(tst_series.name),\n",
    "        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n",
    "        on=tst_series.name,\n",
    "        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n",
    "    \n",
    "    # pd.merge does not keep the index so restore it\n",
    "    ft_tst_series.index = tst_series.index\n",
    "    \n",
    "    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./porto_seguro/train.csv', na_values=\"-1\")\n",
    "test_df = pd.read_csv('./porto_seguro/test.csv', na_values=\"-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from olivier\n",
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "    \"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "    \"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "    \"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "    \"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "    \"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "    \"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "    \"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "    \"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "    \"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "    \"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n",
    "    \"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "    \"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "    \"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "    \"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "    \"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n",
    "    \"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n",
    "    \"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "    \"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "    \"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n",
    "    \"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "    \"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "    \"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "    \"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "    \"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "    \"ps_calc_09\",  #           :  169.13 / shadow  129.72\n",
    "    \"ps_calc_05\",  #           :  148.83 / shadow  120.68\n",
    "    \"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n",
    "    \"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "    \"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n",
    "    \"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "    \"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n",
    "    \"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "    \"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "]\n",
    "\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_02_cat    1 in   0.0\n",
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.0\n"
     ]
    }
   ],
   "source": [
    "# Process data\n",
    "id_test = test_df['id'].values\n",
    "id_train = train_df['id'].values\n",
    "y = train_df['target']\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60))\n",
    "    \n",
    "    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n",
    "    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n",
    "    \n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n",
    "    train_df[name1] = lbl.transform(list(train_df[name1].values))\n",
    "    test_df[name1] = lbl.transform(list(test_df[name1].values))\n",
    "\n",
    "    train_features.append(name1)\n",
    "    \n",
    "X = train_df[train_features]\n",
    "test_df = test_df[train_features]\n",
    "\n",
    "f_cats = [f for f in X.columns if \"_cat\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = 0 * y\n",
    "y_test_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up folds\n",
    "K = 5\n",
    "kf = StratifiedKFold(n_splits=K, random_state=1, shuffle=True)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up classifier\n",
    "model = XGBClassifier(    \n",
    "                        n_estimators=MAX_ROUNDS,\n",
    "                        max_depth=4,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=LEARNING_RATE, \n",
    "                        subsample=.8,\n",
    "                        min_child_weight=6,\n",
    "                        colsample_bytree=.8,\n",
    "                        scale_pos_weight=1.6,\n",
    "                        gamma=10,\n",
    "                        reg_alpha=8,\n",
    "                        reg_lambda=1.3,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "[20:59:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2782370292877412\n",
      "\n",
      "Fold  1\n",
      "[21:00:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.280692079296757\n",
      "\n",
      "Fold  2\n",
      "[21:01:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2867285610185394\n",
      "\n",
      "Fold  3\n",
      "[21:02:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2864232547656165\n",
      "\n",
      "Fold  4\n",
      "[21:03:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "  Gini =  0.2918269435375388\n",
      "\n",
      "Gini for full training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2847372930699126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run CV\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train_df, train_df[\"target\"])):\n",
    "    \n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n",
    "    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n",
    "    X_test = test_df.copy()\n",
    "    print( \"\\nFold \", i)\n",
    "    \n",
    "    # Enocode data\n",
    "    for f in f_cats:\n",
    "        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n",
    "                                                        trn_series=X_train[f],\n",
    "                                                        val_series=X_valid[f],\n",
    "                                                        tst_series=X_test[f],\n",
    "                                                        target=y_train,\n",
    "                                                        min_samples_leaf=200,\n",
    "                                                        smoothing=10,\n",
    "                                                        noise_level=0\n",
    "                                                        )\n",
    "    # Run model for this fold\n",
    "    if OPTIMIZE_ROUNDS:\n",
    "        eval_set=[(X_valid,y_valid)]\n",
    "        fit_model = model.fit( X_train, y_train, \n",
    "                               eval_set=eval_set,\n",
    "                               eval_metric=gini_xgb,\n",
    "                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "                               verbose=False\n",
    "                             )\n",
    "        print( \"  Best N trees = \", model.best_ntree_limit )\n",
    "        print( \"  Best gini = \", model.best_score )\n",
    "    else:\n",
    "        fit_model = model.fit( X_train, y_train )\n",
    "        \n",
    "    # Generate validation predictions for this fold\n",
    "    pred = fit_model.predict_proba(X_valid)[:,1]\n",
    "    # predict_proba의 출력은 각 클래스에 대한 확률, 이진 분류에서는 항상 사이즈가 (n_samples, 2)\n",
    "    print(\"  Gini = \", eval_gini(y_valid, pred))\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # Accumulate test set predictions\n",
    "    y_test_pred += fit_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    del X_test, X_train, X_valid, y_train\n",
    "    \n",
    "y_test_pred /= K\n",
    "\n",
    "print( \"\\nGini for full training set:\" )\n",
    "eval_gini(y, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save validation predictions for stacking/ensembling\n",
    "val = pd.DataFrame()\n",
    "val['id'] = id_train\n",
    "val['target'] = y_valid_pred.values\n",
    "val.to_csv('xgb_valid.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_test_pred\n",
    "sub.to_csv('xgb_submit.csv', float_format='%.6f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
